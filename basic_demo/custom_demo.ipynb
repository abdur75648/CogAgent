{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-25 00:07:08,179] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Rank:  0\n",
      "World size:  1\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(\"/workspace/CogAgent/basic_demo\"))\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import torch\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from sat.mpu import get_model_parallel_world_size\n",
    "from sat.model import AutoModel\n",
    "from utils.utils import chat, llama2_tokenizer, llama2_text_processor, get_image_processor, parse_response, get_grounding_image_processor\n",
    "from utils.models import CogAgentModel, CogVLMModel\n",
    "from utils.utils import TestItemDataset as ItemDataset\n",
    "from sat.training.deepspeed_training import inference_main\n",
    "rank = int(os.environ.get('RANK', 0))\n",
    "world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
    "\n",
    "print(\"Rank: \", rank)\n",
    "print(\"World size: \", world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_demo import data_collator, load_model, create_dataset_function, forward_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens:  32000\n",
      "Using VG token:  给  with index:  31999\n",
      "\n",
      "\n",
      "args: Namespace(from_pretrained='../finetune_demo/checkpoints/finetune-cogagent-vqa-03-21-19-37/', local_tokenizer='lmsys/vicuna-7b-v1.5', max_length=1024, top_p=0.4, top_k=1, temperature=0.8, version='chat_old', quant=None, fp16=True, bf16=False, stream_chat=False, gnd_image_pix=512, use_lora=True, vg_token_idx=31999)\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "from utils.utils import llama2_tokenizer\n",
    "\n",
    "# Define your arguments\n",
    "args = Namespace(\n",
    "    from_pretrained=\"../finetune_demo/checkpoints/finetune-cogagent-vqa-03-21-19-37/\",\n",
    "    local_tokenizer=\"lmsys/vicuna-7b-v1.5\",\n",
    "    max_length=1024,\n",
    "    top_p=0.4,\n",
    "    top_k=1,\n",
    "    temperature=0.8,\n",
    "    version=\"chat_old\",\n",
    "    quant=None,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    stream_chat=False,\n",
    "    gnd_image_pix=512,\n",
    "    use_lora=True\n",
    ")\n",
    "\n",
    "vg_token = \"给\"\n",
    "tokenizer = llama2_tokenizer(args.local_tokenizer, signal_type=args.version)\n",
    "args.vg_token_idx = tokenizer.convert_tokens_to_ids(vg_token)\n",
    "\n",
    "print(\"Total number of tokens: \", tokenizer.vocab_size)\n",
    "print(\"Using VG token: \", vg_token, \" with index: \", args.vg_token_idx)\n",
    "print(\"\\n\\nargs:\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-25 00:07:14,571] [INFO] building FineTuneTrainCogAgentModelNew model ...\n",
      "[2024-03-25 00:07:14,575] [INFO] [RANK 0] > initializing model parallel with size 1\n",
      "[2024-03-25 00:07:14,576] [INFO] [RANK 0] You didn't pass in LOCAL_WORLD_SIZE environment variable. We use the guessed LOCAL_WORLD_SIZE=1. If this is wrong, please pass the LOCAL_WORLD_SIZE manually.\n",
      "[2024-03-25 00:07:14,577] [INFO] [RANK 0] You are using model-only mode.\n",
      "For torch.distributed users or loading model parallel models, set environment variables RANK, WORLD_SIZE and LOCAL_RANK.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained groundindino model from ../groundingdino_swinb_cogcoor.pth with msg: _IncompatibleKeys(missing_keys=['transformer.tgt_embed.weight'], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids', 'bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'feat_map.weight', 'feat_map.bias'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-25 00:08:52,486] [INFO] [RANK 0]  > number of parameters on model parallel rank 0: 18432088128\n",
      "INFO:sat:[RANK 0]  > number of parameters on model parallel rank 0: 18432088128\n",
      "[2024-03-25 00:09:59,173] [INFO] [RANK 0] \n",
      "\n",
      "Adding LoRA to the model for inference. Expecting the model weights to be in the LoRA format. If not, please stop the process and fix it\n",
      "\\m\n",
      "INFO:sat:[RANK 0] \n",
      "\n",
      "Adding LoRA to the model for inference. Expecting the model weights to be in the LoRA format. If not, please stop the process and fix it\n",
      "\\m\n",
      "[2024-03-25 00:09:59,178] [INFO] [RANK 0] replacing layer 0 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 0 attention with lora\n",
      "[2024-03-25 00:10:00,213] [INFO] [RANK 0] replacing layer 0 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 0 cross attention with lora\n",
      "[2024-03-25 00:10:00,971] [INFO] [RANK 0] replacing layer 1 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 1 attention with lora\n",
      "[2024-03-25 00:10:02,108] [INFO] [RANK 0] replacing layer 1 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 1 cross attention with lora\n",
      "[2024-03-25 00:10:02,878] [INFO] [RANK 0] replacing layer 2 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 2 attention with lora\n",
      "[2024-03-25 00:10:04,115] [INFO] [RANK 0] replacing layer 2 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 2 cross attention with lora\n",
      "[2024-03-25 00:10:04,774] [INFO] [RANK 0] replacing layer 3 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 3 attention with lora\n",
      "[2024-03-25 00:10:05,709] [INFO] [RANK 0] replacing layer 3 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 3 cross attention with lora\n",
      "[2024-03-25 00:10:06,072] [INFO] [RANK 0] replacing layer 4 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 4 attention with lora\n",
      "[2024-03-25 00:10:07,413] [INFO] [RANK 0] replacing layer 4 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 4 cross attention with lora\n",
      "[2024-03-25 00:10:07,592] [INFO] [RANK 0] replacing layer 5 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 5 attention with lora\n",
      "[2024-03-25 00:10:08,827] [INFO] [RANK 0] replacing layer 5 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 5 cross attention with lora\n",
      "[2024-03-25 00:10:09,475] [INFO] [RANK 0] replacing layer 6 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 6 attention with lora\n",
      "[2024-03-25 00:10:10,608] [INFO] [RANK 0] replacing layer 6 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 6 cross attention with lora\n",
      "[2024-03-25 00:10:10,784] [INFO] [RANK 0] replacing layer 7 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 7 attention with lora\n",
      "[2024-03-25 00:10:12,113] [INFO] [RANK 0] replacing layer 7 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 7 cross attention with lora\n",
      "[2024-03-25 00:10:12,380] [INFO] [RANK 0] replacing layer 8 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 8 attention with lora\n",
      "[2024-03-25 00:10:13,416] [INFO] [RANK 0] replacing layer 8 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 8 cross attention with lora\n",
      "[2024-03-25 00:10:13,878] [INFO] [RANK 0] replacing layer 9 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 9 attention with lora\n",
      "[2024-03-25 00:10:15,113] [INFO] [RANK 0] replacing layer 9 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 9 cross attention with lora\n",
      "[2024-03-25 00:10:15,494] [INFO] [RANK 0] replacing layer 10 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 10 attention with lora\n",
      "[2024-03-25 00:10:16,705] [INFO] [RANK 0] replacing layer 10 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 10 cross attention with lora\n",
      "[2024-03-25 00:10:17,473] [INFO] [RANK 0] replacing layer 11 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 11 attention with lora\n",
      "[2024-03-25 00:10:18,310] [INFO] [RANK 0] replacing layer 11 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 11 cross attention with lora\n",
      "[2024-03-25 00:10:18,875] [INFO] [RANK 0] replacing layer 12 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 12 attention with lora\n",
      "[2024-03-25 00:10:20,114] [INFO] [RANK 0] replacing layer 12 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 12 cross attention with lora\n",
      "[2024-03-25 00:10:20,679] [INFO] [RANK 0] replacing layer 13 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 13 attention with lora\n",
      "[2024-03-25 00:10:21,916] [INFO] [RANK 0] replacing layer 13 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 13 cross attention with lora\n",
      "[2024-03-25 00:10:22,377] [INFO] [RANK 0] replacing layer 14 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 14 attention with lora\n",
      "[2024-03-25 00:10:23,605] [INFO] [RANK 0] replacing layer 14 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 14 cross attention with lora\n",
      "[2024-03-25 00:10:23,773] [INFO] [RANK 0] replacing layer 15 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 15 attention with lora\n",
      "[2024-03-25 00:10:24,714] [INFO] [RANK 0] replacing layer 15 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 15 cross attention with lora\n",
      "[2024-03-25 00:10:24,985] [INFO] [RANK 0] replacing layer 16 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 16 attention with lora\n",
      "[2024-03-25 00:10:26,416] [INFO] [RANK 0] replacing layer 16 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 16 cross attention with lora\n",
      "[2024-03-25 00:10:27,172] [INFO] [RANK 0] replacing layer 17 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 17 attention with lora\n",
      "[2024-03-25 00:10:28,316] [INFO] [RANK 0] replacing layer 17 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 17 cross attention with lora\n",
      "[2024-03-25 00:10:29,073] [INFO] [RANK 0] replacing layer 18 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 18 attention with lora\n",
      "[2024-03-25 00:10:30,209] [INFO] [RANK 0] replacing layer 18 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 18 cross attention with lora\n",
      "[2024-03-25 00:10:30,972] [INFO] [RANK 0] replacing layer 19 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 19 attention with lora\n",
      "[2024-03-25 00:10:31,902] [INFO] [RANK 0] replacing layer 19 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 19 cross attention with lora\n",
      "[2024-03-25 00:10:32,076] [INFO] [RANK 0] replacing layer 20 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 20 attention with lora\n",
      "[2024-03-25 00:10:33,010] [INFO] [RANK 0] replacing layer 20 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 20 cross attention with lora\n",
      "[2024-03-25 00:10:33,285] [INFO] [RANK 0] replacing layer 21 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 21 attention with lora\n",
      "[2024-03-25 00:10:34,431] [INFO] [RANK 0] replacing layer 21 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 21 cross attention with lora\n",
      "[2024-03-25 00:10:35,073] [INFO] [RANK 0] replacing layer 22 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 22 attention with lora\n",
      "[2024-03-25 00:10:36,484] [INFO] [RANK 0] replacing layer 22 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 22 cross attention with lora\n",
      "[2024-03-25 00:10:36,686] [INFO] [RANK 0] replacing layer 23 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 23 attention with lora\n",
      "[2024-03-25 00:10:37,612] [INFO] [RANK 0] replacing layer 23 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 23 cross attention with lora\n",
      "[2024-03-25 00:10:37,975] [INFO] [RANK 0] replacing layer 24 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 24 attention with lora\n",
      "[2024-03-25 00:10:39,313] [INFO] [RANK 0] replacing layer 24 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 24 cross attention with lora\n",
      "[2024-03-25 00:10:39,869] [INFO] [RANK 0] replacing layer 25 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 25 attention with lora\n",
      "[2024-03-25 00:10:40,923] [INFO] [RANK 0] replacing layer 25 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 25 cross attention with lora\n",
      "[2024-03-25 00:10:41,182] [INFO] [RANK 0] replacing layer 26 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 26 attention with lora\n",
      "[2024-03-25 00:10:42,512] [INFO] [RANK 0] replacing layer 26 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 26 cross attention with lora\n",
      "[2024-03-25 00:10:42,980] [INFO] [RANK 0] replacing layer 27 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 27 attention with lora\n",
      "[2024-03-25 00:10:44,182] [INFO] [RANK 0] replacing layer 27 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 27 cross attention with lora\n",
      "[2024-03-25 00:10:44,381] [INFO] [RANK 0] replacing layer 28 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 28 attention with lora\n",
      "[2024-03-25 00:10:45,412] [INFO] [RANK 0] replacing layer 28 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 28 cross attention with lora\n",
      "[2024-03-25 00:10:45,777] [INFO] [RANK 0] replacing layer 29 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 29 attention with lora\n",
      "[2024-03-25 00:10:46,811] [INFO] [RANK 0] replacing layer 29 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 29 cross attention with lora\n",
      "[2024-03-25 00:10:47,085] [INFO] [RANK 0] replacing layer 30 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 30 attention with lora\n",
      "[2024-03-25 00:10:48,071] [INFO] [RANK 0] replacing layer 30 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 30 cross attention with lora\n",
      "[2024-03-25 00:10:48,773] [INFO] [RANK 0] replacing layer 31 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 31 attention with lora\n",
      "[2024-03-25 00:10:49,911] [INFO] [RANK 0] replacing layer 31 cross attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 31 cross attention with lora\n",
      "[2024-03-25 00:10:50,580] [INFO] [RANK 0] replacing layer 0 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 0 attention with lora\n",
      "[2024-03-25 00:10:50,978] [INFO] [RANK 0] replacing layer 1 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 1 attention with lora\n",
      "[2024-03-25 00:10:51,684] [INFO] [RANK 0] replacing layer 2 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 2 attention with lora\n",
      "[2024-03-25 00:10:52,283] [INFO] [RANK 0] replacing layer 3 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 3 attention with lora\n",
      "[2024-03-25 00:10:52,980] [INFO] [RANK 0] replacing layer 4 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 4 attention with lora\n",
      "[2024-03-25 00:10:53,669] [INFO] [RANK 0] replacing layer 5 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 5 attention with lora\n",
      "[2024-03-25 00:10:54,279] [INFO] [RANK 0] replacing layer 6 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 6 attention with lora\n",
      "[2024-03-25 00:10:54,975] [INFO] [RANK 0] replacing layer 7 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 7 attention with lora\n",
      "[2024-03-25 00:10:55,680] [INFO] [RANK 0] replacing layer 8 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 8 attention with lora\n",
      "[2024-03-25 00:10:56,378] [INFO] [RANK 0] replacing layer 9 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 9 attention with lora\n",
      "[2024-03-25 00:10:57,070] [INFO] [RANK 0] replacing layer 10 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 10 attention with lora\n",
      "[2024-03-25 00:10:57,572] [INFO] [RANK 0] replacing layer 11 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 11 attention with lora\n",
      "[2024-03-25 00:10:58,178] [INFO] [RANK 0] replacing layer 12 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 12 attention with lora\n",
      "[2024-03-25 00:10:58,870] [INFO] [RANK 0] replacing layer 13 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 13 attention with lora\n",
      "[2024-03-25 00:10:59,573] [INFO] [RANK 0] replacing layer 14 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 14 attention with lora\n",
      "[2024-03-25 00:11:00,178] [INFO] [RANK 0] replacing layer 15 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 15 attention with lora\n",
      "[2024-03-25 00:11:00,879] [INFO] [RANK 0] replacing layer 16 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 16 attention with lora\n",
      "[2024-03-25 00:11:01,578] [INFO] [RANK 0] replacing layer 17 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 17 attention with lora\n",
      "[2024-03-25 00:11:02,282] [INFO] [RANK 0] replacing layer 18 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 18 attention with lora\n",
      "[2024-03-25 00:11:02,977] [INFO] [RANK 0] replacing layer 19 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 19 attention with lora\n",
      "[2024-03-25 00:11:03,678] [INFO] [RANK 0] replacing layer 20 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 20 attention with lora\n",
      "[2024-03-25 00:11:04,377] [INFO] [RANK 0] replacing layer 21 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 21 attention with lora\n",
      "[2024-03-25 00:11:05,078] [INFO] [RANK 0] replacing layer 22 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 22 attention with lora\n",
      "[2024-03-25 00:11:05,376] [INFO] [RANK 0] replacing layer 23 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 23 attention with lora\n",
      "[2024-03-25 00:11:05,670] [INFO] [RANK 0] replacing layer 24 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 24 attention with lora\n",
      "[2024-03-25 00:11:06,170] [INFO] [RANK 0] replacing layer 25 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 25 attention with lora\n",
      "[2024-03-25 00:11:06,573] [INFO] [RANK 0] replacing layer 26 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 26 attention with lora\n",
      "[2024-03-25 00:11:07,173] [INFO] [RANK 0] replacing layer 27 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 27 attention with lora\n",
      "[2024-03-25 00:11:07,470] [INFO] [RANK 0] replacing layer 28 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 28 attention with lora\n",
      "[2024-03-25 00:11:07,970] [INFO] [RANK 0] replacing layer 29 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 29 attention with lora\n",
      "[2024-03-25 00:11:08,370] [INFO] [RANK 0] replacing layer 30 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 30 attention with lora\n",
      "[2024-03-25 00:11:08,978] [INFO] [RANK 0] replacing layer 31 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 31 attention with lora\n",
      "[2024-03-25 00:11:09,378] [INFO] [RANK 0] replacing layer 32 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 32 attention with lora\n",
      "[2024-03-25 00:11:09,674] [INFO] [RANK 0] replacing layer 33 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 33 attention with lora\n",
      "[2024-03-25 00:11:10,273] [INFO] [RANK 0] replacing layer 34 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 34 attention with lora\n",
      "[2024-03-25 00:11:10,574] [INFO] [RANK 0] replacing layer 35 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 35 attention with lora\n",
      "[2024-03-25 00:11:11,370] [INFO] [RANK 0] replacing layer 36 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 36 attention with lora\n",
      "[2024-03-25 00:11:11,770] [INFO] [RANK 0] replacing layer 37 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 37 attention with lora\n",
      "[2024-03-25 00:11:12,373] [INFO] [RANK 0] replacing layer 38 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 38 attention with lora\n",
      "[2024-03-25 00:11:12,868] [INFO] [RANK 0] replacing layer 39 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 39 attention with lora\n",
      "[2024-03-25 00:11:13,573] [INFO] [RANK 0] replacing layer 40 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 40 attention with lora\n",
      "[2024-03-25 00:11:14,282] [INFO] [RANK 0] replacing layer 41 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 41 attention with lora\n",
      "[2024-03-25 00:11:14,972] [INFO] [RANK 0] replacing layer 42 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 42 attention with lora\n",
      "[2024-03-25 00:11:15,269] [INFO] [RANK 0] replacing layer 43 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 43 attention with lora\n",
      "[2024-03-25 00:11:16,079] [INFO] [RANK 0] replacing layer 44 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 44 attention with lora\n",
      "[2024-03-25 00:11:16,770] [INFO] [RANK 0] replacing layer 45 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 45 attention with lora\n",
      "[2024-03-25 00:11:17,170] [INFO] [RANK 0] replacing layer 46 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 46 attention with lora\n",
      "[2024-03-25 00:11:17,778] [INFO] [RANK 0] replacing layer 47 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 47 attention with lora\n",
      "[2024-03-25 00:11:18,373] [INFO] [RANK 0] replacing layer 48 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 48 attention with lora\n",
      "[2024-03-25 00:11:18,670] [INFO] [RANK 0] replacing layer 49 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 49 attention with lora\n",
      "[2024-03-25 00:11:18,873] [INFO] [RANK 0] replacing layer 50 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 50 attention with lora\n",
      "[2024-03-25 00:11:19,270] [INFO] [RANK 0] replacing layer 51 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 51 attention with lora\n",
      "[2024-03-25 00:11:19,982] [INFO] [RANK 0] replacing layer 52 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 52 attention with lora\n",
      "[2024-03-25 00:11:20,674] [INFO] [RANK 0] replacing layer 53 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 53 attention with lora\n",
      "[2024-03-25 00:11:21,383] [INFO] [RANK 0] replacing layer 54 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 54 attention with lora\n",
      "[2024-03-25 00:11:22,170] [INFO] [RANK 0] replacing layer 55 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 55 attention with lora\n",
      "[2024-03-25 00:11:22,473] [INFO] [RANK 0] replacing layer 56 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 56 attention with lora\n",
      "[2024-03-25 00:11:22,869] [INFO] [RANK 0] replacing layer 57 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 57 attention with lora\n",
      "[2024-03-25 00:11:23,169] [INFO] [RANK 0] replacing layer 58 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 58 attention with lora\n",
      "[2024-03-25 00:11:24,070] [INFO] [RANK 0] replacing layer 59 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 59 attention with lora\n",
      "[2024-03-25 00:11:24,870] [INFO] [RANK 0] replacing layer 60 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 60 attention with lora\n",
      "[2024-03-25 00:11:25,579] [INFO] [RANK 0] replacing layer 61 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 61 attention with lora\n",
      "[2024-03-25 00:11:26,285] [INFO] [RANK 0] replacing layer 62 attention with lora\n",
      "INFO:sat:[RANK 0] replacing layer 62 attention with lora\n",
      "[2024-03-25 00:11:27,034] [INFO] [RANK 0] global rank 0 is loading checkpoint ../finetune_demo/checkpoints/finetune-cogagent-vqa-03-21-19-37/3000/mp_rank_00_model_states.pt\n",
      "INFO:sat:[RANK 0] global rank 0 is loading checkpoint ../finetune_demo/checkpoints/finetune-cogagent-vqa-03-21-19-37/3000/mp_rank_00_model_states.pt\n",
      "[2024-03-25 00:14:29,704] [INFO] [RANK 0] > successfully loaded ../finetune_demo/checkpoints/finetune-cogagent-vqa-03-21-19-37/3000/mp_rank_00_model_states.pt\n",
      "INFO:sat:[RANK 0] > successfully loaded ../finetune_demo/checkpoints/finetune-cogagent-vqa-03-21-19-37/3000/mp_rank_00_model_states.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ready For Inference\n",
      "Model Size:  18552.612928 M\n"
     ]
    }
   ],
   "source": [
    "model, image_processor, cross_image_processor, text_processor_infer, grounding_image_processor = load_model(args)\n",
    "print(\"Model Ready For Inference\", flush=True)\n",
    "print(\"Model Size: \", sum(p.numel() for p in model.parameters())/1e6, \"M\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuneTrainCogAgentModelNew(\n",
      "  (mixins): ModuleDict(\n",
      "    (lm): LMMixin(\n",
      "      (lm_head): ColumnParallelLinear()\n",
      "    )\n",
      "    (eva): ImageMixin(\n",
      "      (vit_model): EVA2CLIPModel(\n",
      "        (mixins): ModuleDict(\n",
      "          (patch_embedding): ImagePatchEmbeddingMixin(\n",
      "            (proj): Conv2d(3, 1792, kernel_size=(14, 14), stride=(14, 14))\n",
      "          )\n",
      "          (pos_embedding): InterpolatedPositionEmbeddingMixin()\n",
      "          (final): IdentityMixin()\n",
      "          (newpost): NewLayerForward()\n",
      "          (xattn): XAttn()\n",
      "          (lora): LoraMixin()\n",
      "        )\n",
      "        (transformer): BaseTransformer(\n",
      "          (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (word_embeddings): Embedding(1, 1792)\n",
      "          (position_embeddings): Embedding(257, 1792)\n",
      "          (layers): ModuleList(\n",
      "            (0-62): 63 x BaseTransformerLayer(\n",
      "              (input_layernorm): LayerNorm(torch.Size([1792]), eps=1e-06, elementwise_affine=True)\n",
      "              (attention): SelfAttention(\n",
      "                (query_key_value): LoraLinear(\n",
      "                  (original): HackColumnParallelLinear()\n",
      "                  (matrix_A): HackParameterList(\n",
      "                      (0): Parameter containing: [torch.float16 of size 50x1792 (cuda:0)]\n",
      "                      (1): Parameter containing: [torch.float16 of size 50x1792 (cuda:0)]\n",
      "                      (2): Parameter containing: [torch.float16 of size 50x1792 (cuda:0)]\n",
      "                  )\n",
      "                  (matrix_B): HackParameterList(\n",
      "                      (0): Parameter containing: [torch.float16 of size 1792x50 (cuda:0)]\n",
      "                      (1): Parameter containing: [torch.float16 of size 1792x50 (cuda:0)]\n",
      "                      (2): Parameter containing: [torch.float16 of size 1792x50 (cuda:0)]\n",
      "                  )\n",
      "                )\n",
      "                (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (dense): LoraLinear(\n",
      "                  (original): HackRowParallelLinear()\n",
      "                  (matrix_A): HackParameterList(  (0): Parameter containing: [torch.float16 of size 50x1792 (cuda:0)])\n",
      "                  (matrix_B): HackParameterList(  (0): Parameter containing: [torch.float16 of size 1792x50 (cuda:0)])\n",
      "                )\n",
      "                (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (post_attention_layernorm): LayerNorm(torch.Size([1792]), eps=1e-06, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (dense_h_to_4h): ColumnParallelLinear()\n",
      "                (dense_4h_to_h): RowParallelLinear()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (linear_proj): GLU(\n",
      "        (linear_proj): Linear(in_features=1792, out_features=4096, bias=False)\n",
      "        (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (act1): GELU(approximate='none')\n",
      "        (dense_h_to_4h): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (dense_4h_to_h): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (mlp): LlamaVisionExpertFCMixin(\n",
      "      (gate_proj): ModuleList(\n",
      "        (0-31): 32 x ColumnParallelLinear()\n",
      "      )\n",
      "      (vision_dense_h_to_4h_list): ModuleDict(\n",
      "        (0): ColumnParallelLinear()\n",
      "        (1): ColumnParallelLinear()\n",
      "        (2): ColumnParallelLinear()\n",
      "        (3): ColumnParallelLinear()\n",
      "        (4): ColumnParallelLinear()\n",
      "        (5): ColumnParallelLinear()\n",
      "        (6): ColumnParallelLinear()\n",
      "        (7): ColumnParallelLinear()\n",
      "        (8): ColumnParallelLinear()\n",
      "        (9): ColumnParallelLinear()\n",
      "        (10): ColumnParallelLinear()\n",
      "        (11): ColumnParallelLinear()\n",
      "        (12): ColumnParallelLinear()\n",
      "        (13): ColumnParallelLinear()\n",
      "        (14): ColumnParallelLinear()\n",
      "        (15): ColumnParallelLinear()\n",
      "        (16): ColumnParallelLinear()\n",
      "        (17): ColumnParallelLinear()\n",
      "        (18): ColumnParallelLinear()\n",
      "        (19): ColumnParallelLinear()\n",
      "        (20): ColumnParallelLinear()\n",
      "        (21): ColumnParallelLinear()\n",
      "        (22): ColumnParallelLinear()\n",
      "        (23): ColumnParallelLinear()\n",
      "        (24): ColumnParallelLinear()\n",
      "        (25): ColumnParallelLinear()\n",
      "        (26): ColumnParallelLinear()\n",
      "        (27): ColumnParallelLinear()\n",
      "        (28): ColumnParallelLinear()\n",
      "        (29): ColumnParallelLinear()\n",
      "        (30): ColumnParallelLinear()\n",
      "        (31): ColumnParallelLinear()\n",
      "      )\n",
      "      (vision_dense_4h_to_h_list): ModuleDict(\n",
      "        (0): RowParallelLinear()\n",
      "        (1): RowParallelLinear()\n",
      "        (2): RowParallelLinear()\n",
      "        (3): RowParallelLinear()\n",
      "        (4): RowParallelLinear()\n",
      "        (5): RowParallelLinear()\n",
      "        (6): RowParallelLinear()\n",
      "        (7): RowParallelLinear()\n",
      "        (8): RowParallelLinear()\n",
      "        (9): RowParallelLinear()\n",
      "        (10): RowParallelLinear()\n",
      "        (11): RowParallelLinear()\n",
      "        (12): RowParallelLinear()\n",
      "        (13): RowParallelLinear()\n",
      "        (14): RowParallelLinear()\n",
      "        (15): RowParallelLinear()\n",
      "        (16): RowParallelLinear()\n",
      "        (17): RowParallelLinear()\n",
      "        (18): RowParallelLinear()\n",
      "        (19): RowParallelLinear()\n",
      "        (20): RowParallelLinear()\n",
      "        (21): RowParallelLinear()\n",
      "        (22): RowParallelLinear()\n",
      "        (23): RowParallelLinear()\n",
      "        (24): RowParallelLinear()\n",
      "        (25): RowParallelLinear()\n",
      "        (26): RowParallelLinear()\n",
      "        (27): RowParallelLinear()\n",
      "        (28): RowParallelLinear()\n",
      "        (29): RowParallelLinear()\n",
      "        (30): RowParallelLinear()\n",
      "        (31): RowParallelLinear()\n",
      "      )\n",
      "      (vision_gate_proj): ModuleDict(\n",
      "        (0): ColumnParallelLinear()\n",
      "        (1): ColumnParallelLinear()\n",
      "        (2): ColumnParallelLinear()\n",
      "        (3): ColumnParallelLinear()\n",
      "        (4): ColumnParallelLinear()\n",
      "        (5): ColumnParallelLinear()\n",
      "        (6): ColumnParallelLinear()\n",
      "        (7): ColumnParallelLinear()\n",
      "        (8): ColumnParallelLinear()\n",
      "        (9): ColumnParallelLinear()\n",
      "        (10): ColumnParallelLinear()\n",
      "        (11): ColumnParallelLinear()\n",
      "        (12): ColumnParallelLinear()\n",
      "        (13): ColumnParallelLinear()\n",
      "        (14): ColumnParallelLinear()\n",
      "        (15): ColumnParallelLinear()\n",
      "        (16): ColumnParallelLinear()\n",
      "        (17): ColumnParallelLinear()\n",
      "        (18): ColumnParallelLinear()\n",
      "        (19): ColumnParallelLinear()\n",
      "        (20): ColumnParallelLinear()\n",
      "        (21): ColumnParallelLinear()\n",
      "        (22): ColumnParallelLinear()\n",
      "        (23): ColumnParallelLinear()\n",
      "        (24): ColumnParallelLinear()\n",
      "        (25): ColumnParallelLinear()\n",
      "        (26): ColumnParallelLinear()\n",
      "        (27): ColumnParallelLinear()\n",
      "        (28): ColumnParallelLinear()\n",
      "        (29): ColumnParallelLinear()\n",
      "        (30): ColumnParallelLinear()\n",
      "        (31): ColumnParallelLinear()\n",
      "      )\n",
      "    )\n",
      "    (rotary): LlamaVisionExpertAttnMixin(\n",
      "      (rotary_emb): FastRotaryEmbedding()\n",
      "      (vision_query_key_value_list): ModuleDict(\n",
      "        (0): ColumnParallelLinear()\n",
      "        (1): ColumnParallelLinear()\n",
      "        (2): ColumnParallelLinear()\n",
      "        (3): ColumnParallelLinear()\n",
      "        (4): ColumnParallelLinear()\n",
      "        (5): ColumnParallelLinear()\n",
      "        (6): ColumnParallelLinear()\n",
      "        (7): ColumnParallelLinear()\n",
      "        (8): ColumnParallelLinear()\n",
      "        (9): ColumnParallelLinear()\n",
      "        (10): ColumnParallelLinear()\n",
      "        (11): ColumnParallelLinear()\n",
      "        (12): ColumnParallelLinear()\n",
      "        (13): ColumnParallelLinear()\n",
      "        (14): ColumnParallelLinear()\n",
      "        (15): ColumnParallelLinear()\n",
      "        (16): ColumnParallelLinear()\n",
      "        (17): ColumnParallelLinear()\n",
      "        (18): ColumnParallelLinear()\n",
      "        (19): ColumnParallelLinear()\n",
      "        (20): ColumnParallelLinear()\n",
      "        (21): ColumnParallelLinear()\n",
      "        (22): ColumnParallelLinear()\n",
      "        (23): ColumnParallelLinear()\n",
      "        (24): ColumnParallelLinear()\n",
      "        (25): ColumnParallelLinear()\n",
      "        (26): ColumnParallelLinear()\n",
      "        (27): ColumnParallelLinear()\n",
      "        (28): ColumnParallelLinear()\n",
      "        (29): ColumnParallelLinear()\n",
      "        (30): ColumnParallelLinear()\n",
      "        (31): ColumnParallelLinear()\n",
      "      )\n",
      "      (vision_dense_list): ModuleDict(\n",
      "        (0): RowParallelLinear()\n",
      "        (1): RowParallelLinear()\n",
      "        (2): RowParallelLinear()\n",
      "        (3): RowParallelLinear()\n",
      "        (4): RowParallelLinear()\n",
      "        (5): RowParallelLinear()\n",
      "        (6): RowParallelLinear()\n",
      "        (7): RowParallelLinear()\n",
      "        (8): RowParallelLinear()\n",
      "        (9): RowParallelLinear()\n",
      "        (10): RowParallelLinear()\n",
      "        (11): RowParallelLinear()\n",
      "        (12): RowParallelLinear()\n",
      "        (13): RowParallelLinear()\n",
      "        (14): RowParallelLinear()\n",
      "        (15): RowParallelLinear()\n",
      "        (16): RowParallelLinear()\n",
      "        (17): RowParallelLinear()\n",
      "        (18): RowParallelLinear()\n",
      "        (19): RowParallelLinear()\n",
      "        (20): RowParallelLinear()\n",
      "        (21): RowParallelLinear()\n",
      "        (22): RowParallelLinear()\n",
      "        (23): RowParallelLinear()\n",
      "        (24): RowParallelLinear()\n",
      "        (25): RowParallelLinear()\n",
      "        (26): RowParallelLinear()\n",
      "        (27): RowParallelLinear()\n",
      "        (28): RowParallelLinear()\n",
      "        (29): RowParallelLinear()\n",
      "        (30): RowParallelLinear()\n",
      "        (31): RowParallelLinear()\n",
      "      )\n",
      "    )\n",
      "    (grounding): GroundingMixin(\n",
      "      (visual_grounding_model): GroundingDINO(\n",
      "        (transformer): Transformer(\n",
      "          (encoder): TransformerEncoder(\n",
      "            (layers): ModuleList(\n",
      "              (0-5): 6 x DeformableTransformerEncoderLayer(\n",
      "                (self_attn): MultiScaleDeformableAttention(\n",
      "                  (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
      "                  (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
      "                  (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                  (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "                (dropout1): Dropout(p=0.0, inplace=False)\n",
      "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "                (dropout2): Dropout(p=0.0, inplace=False)\n",
      "                (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "                (dropout3): Dropout(p=0.0, inplace=False)\n",
      "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "            (text_layers): ModuleList(\n",
      "              (0-5): 6 x TransformerEncoderLayer(\n",
      "                (self_attn): MultiheadAttention(\n",
      "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "                (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout1): Dropout(p=0.0, inplace=False)\n",
      "                (dropout2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (fusion_layers): ModuleList(\n",
      "              (0-5): 6 x BiAttentionBlock(\n",
      "                (layer_norm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (layer_norm_l): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): BiMultiHeadAttention(\n",
      "                  (v_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (l_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (values_v_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (values_l_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (out_v_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (out_l_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                )\n",
      "                (drop_path): DropPath(drop_prob=0.100)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (decoder): TransformerDecoder(\n",
      "            (layers): ModuleList(\n",
      "              (0-5): 6 x DeformableTransformerDecoderLayer(\n",
      "                (cross_attn): MultiScaleDeformableAttention(\n",
      "                  (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
      "                  (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
      "                  (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                  (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "                (dropout1): Identity()\n",
      "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (ca_text): MultiheadAttention(\n",
      "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "                (catext_dropout): Identity()\n",
      "                (catext_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (self_attn): MultiheadAttention(\n",
      "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "                (dropout2): Identity()\n",
      "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "                (dropout3): Identity()\n",
      "                (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "                (dropout4): Identity()\n",
      "                (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (ref_point_head): MLP(\n",
      "              (layers): ModuleList(\n",
      "                (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (bbox_embed): ModuleList(\n",
      "              (0-5): 6 x MLP(\n",
      "                (layers): ModuleList(\n",
      "                  (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "                  (2): Linear(in_features=256, out_features=4, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (class_embed): ModuleList(\n",
      "              (0-5): 6 x ContrastiveEmbed()\n",
      "            )\n",
      "          )\n",
      "          (tgt_embed): Embedding(900, 256)\n",
      "          (enc_output): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (enc_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (enc_out_bbox_embed): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "              (2): Linear(in_features=256, out_features=4, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (enc_out_class_embed): ContrastiveEmbed()\n",
      "        )\n",
      "        (input_proj): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (backbone): Joiner(\n",
      "          (0): SwinTransformer(\n",
      "            (patch_embed): PatchEmbed(\n",
      "              (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "            (layers): ModuleList(\n",
      "              (0): BasicLayer(\n",
      "                (blocks): ModuleList(\n",
      "                  (0): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): Identity()\n",
      "                    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.009)\n",
      "                    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (downsample): PatchMerging(\n",
      "                  (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "              (1): BasicLayer(\n",
      "                (blocks): ModuleList(\n",
      "                  (0): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.017)\n",
      "                    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.026)\n",
      "                    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (downsample): PatchMerging(\n",
      "                  (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "                  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "              (2): BasicLayer(\n",
      "                (blocks): ModuleList(\n",
      "                  (0): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.035)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.043)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (2): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.052)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (3): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.061)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (4): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.070)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (5): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.078)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (6): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.087)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (7): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.096)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (8): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.104)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (9): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.113)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (10): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.122)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (11): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.130)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (12): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.139)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (13): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.148)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (14): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.157)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (15): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.165)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (16): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.174)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (17): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.183)\n",
      "                    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (downsample): PatchMerging(\n",
      "                  (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "                  (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "              (3): BasicLayer(\n",
      "                (blocks): ModuleList(\n",
      "                  (0): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.191)\n",
      "                    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): SwinTransformerBlock(\n",
      "                    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                    (attn): WindowAttention(\n",
      "                      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "                      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                      (softmax): Softmax(dim=-1)\n",
      "                    )\n",
      "                    (drop_path): DropPath(drop_prob=0.200)\n",
      "                    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                    (mlp): Mlp(\n",
      "                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                      (act): GELU(approximate='none')\n",
      "                      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                      (drop): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (1): PositionEmbeddingSineHW()\n",
      "        )\n",
      "        (bbox_embed): ModuleList(\n",
      "          (0-5): 6 x MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "              (2): Linear(in_features=256, out_features=4, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (class_embed): ModuleList(\n",
      "          (0-5): 6 x ContrastiveEmbed()\n",
      "        )\n",
      "      )\n",
      "      (criterion_grounding): SetCriterion(\n",
      "        (matcher): HungarianMatcher()\n",
      "      )\n",
      "    )\n",
      "    (encoder): ExternalVisionModel(\n",
      "      (vit): Eva2LargeEncoder(\n",
      "        (model): EVAVisionTransformer(\n",
      "          (patch_embed): PatchEmbed(\n",
      "            (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "          )\n",
      "          (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "          (rope): VisionRotaryEmbeddingFast()\n",
      "          (blocks): ModuleList(\n",
      "            (0-23): 24 x Block(\n",
      "              (norm1): FusedLayerNorm(torch.Size([1024]), eps=1e-06, elementwise_affine=True)\n",
      "              (attn): Attention(\n",
      "                (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "                (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "                (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (inner_attn_ln): FusedLayerNorm(torch.Size([1024]), eps=1e-06, elementwise_affine=True)\n",
      "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (rope): VisionRotaryEmbeddingFast()\n",
      "              )\n",
      "              (drop_path): Identity()\n",
      "              (norm2): FusedLayerNorm(torch.Size([1024]), eps=1e-06, elementwise_affine=True)\n",
      "              (mlp): SwiGLU(\n",
      "                (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "                (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "                (act): SiLU()\n",
      "                (ffn_ln): FusedLayerNorm(torch.Size([2730]), eps=1e-06, elementwise_affine=True)\n",
      "                (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
      "                (drop): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (norm): FusedLayerNorm(torch.Size([1024]), eps=1e-06, elementwise_affine=True)\n",
      "          (head): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (patch_dropout): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (lora): LoraMixin()\n",
      "  )\n",
      "  (transformer): BaseTransformer(\n",
      "    (embedding_dropout): Dropout(p=0, inplace=False)\n",
      "    (word_embeddings): VocabParallelEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x BaseTransformerLayer(\n",
      "        (input_layernorm): RMSNorm()\n",
      "        (attention): SelfAttention(\n",
      "          (query_key_value): LoraLinear(\n",
      "            (original): HackColumnParallelLinear()\n",
      "            (matrix_A): HackParameterList(\n",
      "                (0): Parameter containing: [torch.float16 of size 50x4096 (cuda:0)]\n",
      "                (1): Parameter containing: [torch.float16 of size 50x4096 (cuda:0)]\n",
      "                (2): Parameter containing: [torch.float16 of size 50x4096 (cuda:0)]\n",
      "            )\n",
      "            (matrix_B): HackParameterList(\n",
      "                (0): Parameter containing: [torch.float16 of size 4096x50 (cuda:0)]\n",
      "                (1): Parameter containing: [torch.float16 of size 4096x50 (cuda:0)]\n",
      "                (2): Parameter containing: [torch.float16 of size 4096x50 (cuda:0)]\n",
      "            )\n",
      "          )\n",
      "          (attention_dropout): Dropout(p=0, inplace=False)\n",
      "          (dense): LoraLinear(\n",
      "            (original): HackRowParallelLinear()\n",
      "            (matrix_A): HackParameterList(  (0): Parameter containing: [torch.float16 of size 50x4096 (cuda:0)])\n",
      "            (matrix_B): HackParameterList(  (0): Parameter containing: [torch.float16 of size 4096x50 (cuda:0)])\n",
      "          )\n",
      "          (output_dropout): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (post_attention_layernorm): RMSNorm()\n",
      "        (cross_attention): CrossAttention(\n",
      "          (query): LoraLinear(\n",
      "            (original): HackColumnParallelLinear()\n",
      "            (matrix_A): HackParameterList(  (0): Parameter containing: [torch.float16 of size 50x4096 (cuda:0)])\n",
      "            (matrix_B): HackParameterList(  (0): Parameter containing: [torch.float16 of size 1024x50 (cuda:0)])\n",
      "          )\n",
      "          (key_value): LoraLinear(\n",
      "            (original): HackColumnParallelLinear()\n",
      "            (matrix_A): HackParameterList(\n",
      "                (0): Parameter containing: [torch.float16 of size 50x1024 (cuda:0)]\n",
      "                (1): Parameter containing: [torch.float16 of size 50x1024 (cuda:0)]\n",
      "            )\n",
      "            (matrix_B): HackParameterList(\n",
      "                (0): Parameter containing: [torch.float16 of size 1024x50 (cuda:0)]\n",
      "                (1): Parameter containing: [torch.float16 of size 1024x50 (cuda:0)]\n",
      "            )\n",
      "          )\n",
      "          (attention_dropout): Dropout(p=0, inplace=False)\n",
      "          (dense): LoraLinear(\n",
      "            (original): HackRowParallelLinear()\n",
      "            (matrix_A): HackParameterList(  (0): Parameter containing: [torch.float16 of size 50x1024 (cuda:0)])\n",
      "            (matrix_B): HackParameterList(  (0): Parameter containing: [torch.float16 of size 4096x50 (cuda:0)])\n",
      "          )\n",
      "          (output_dropout): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (post_cross_attention_layernorm): RMSNorm()\n",
      "        (mlp): MLP(\n",
      "          (dense_h_to_4h): ColumnParallelLinear()\n",
      "          (dense_4h_to_h): RowParallelLinear()\n",
      "          (dropout): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layernorm): RMSNorm()\n",
      "  )\n",
      "  (grounding_fc): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=4096, out_features=256, bias=True)\n",
      "    (3): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-25 00:14:33,963] [INFO] [RANK 0] find 1 samples in all...\n",
      "INFO:sat:[RANK 0] find 1 samples in all...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data: {'Question': 'Task: Give me the list of all product manager with minimum 5 years of experience working in a series A company with minimum 1M in revenue. \\n Previous Action: None \\nGive me the next action?', 'Answer': 'This is a dummy answer and a dummy [0.179,0.452,0.385,0.51] button', 'workflow': 'anurag-wf-10_augmented_cropped', 'imagePath': '/workspace/CogAgent/test_data//anish-wf-6_a.png'}\n",
      "Creating dataset using the VG token:  给\n"
     ]
    }
   ],
   "source": [
    "dataset_valid = create_dataset_function(image_processor, text_processor_infer, cross_image_processor, grounding_image_processor, vg_token, path=\"../test_data/apollo_ferret_noscale.json\", args=args)\n",
    "data_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=1, collate_fn=partial(data_collator, cross_image_processor=cross_image_processor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Done\n"
     ]
    }
   ],
   "source": [
    "lm_logits, bbox_outputs = inference_main(args, model=model, forward_step_function=forward_step, data_loader=data_loader)\n",
    "print(\"Inference Done\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbox_outputs:  tensor([[[0.0826, 0.1047, 0.1525, 0.0331],\n",
      "         [0.0779, 0.1162, 0.1530, 0.0384],\n",
      "         [0.0924, 0.3704, 0.1726, 0.0319],\n",
      "         ...,\n",
      "         [0.3192, 0.2665, 0.2923, 0.0349],\n",
      "         [0.2221, 0.3241, 0.1146, 0.0330],\n",
      "         [0.2731, 0.4535, 0.1855, 0.0465]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"bbox_outputs: \", bbox_outputs['pred_boxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_logits:  tensor([[[ 1.0371, -0.1876,  0.1923,  ...,  1.2939,  2.1895,  1.4922],\n",
      "         [ 3.2578,  3.2871, -0.4783,  ...,  2.9355,  3.9180,  2.9355],\n",
      "         [-2.6777, -6.6641, -1.6504,  ..., -0.7275, -2.1895, -0.1832],\n",
      "         ...,\n",
      "         [-4.7656,  0.6045, 12.1094,  ..., -0.8701, -4.4258, -0.8740],\n",
      "         [-4.7500,  0.6826, 12.1328,  ..., -0.8037, -4.3867, -0.8442],\n",
      "         [-4.7383,  0.7798, 12.2422,  ..., -0.7568, -4.3555, -0.8159]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"lm_logits: \", lm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_logits:  [23195, 24365, 5496, 285, 659, 29870, 13607, 29870, 29870, 5555, 1721, 29994, 659, 2739, 5066, 3814, 29994, 5066, 398, 1919, 29888, 1018, 381, 4720, 12713, 2739, 29888, 29994, 13607, 29994, 381, 29994, 29994, 1550, 7568, 2760, 29994, 23767, 659, 372, 29994, 1, 29994, 29994, 1, 29994, 29899, 29899, 1, 1, 2190, 1856, 1856, 727, 2626, 1856, 1, 1, 4875, 382, 1856, 1721, 1721, 2626, 11596, 12713, 23767, 7568, 659, 7568, 4817, 27758, 1, 1721, 1, 2626, 12713, 1, 1, 4875, 1, 1, 974, 1856, 1721, 23767, 4817, 4817, 1721, 1721, 1, 1, 1, 1721, 1, 12713, 321, 2626, 7568, 2626, 1431, 7568, 1856, 1721, 1, 1, 1, 1, 4875, 1, 1431, 1, 727, 292, 29955, 1, 2626, 23767, 7568, 382, 2626, 1431, 29994, 730, 1, 1, 1, 1, 382, 12713, 9075, 1856, 292, 7568, 1431, 2701, 2626, 3289, 2626, 730, 1, 382, 382, 382, 1, 1, 7568, 7568, 292, 896, 2190, 382, 29994, 730, 382, 382, 382, 382, 382, 1721, 11596, 29888, 321, 1912, 7932, 5869, 730, 1721, 3289, 896, 1633, 4720, 29994, 382, 382, 382, 382, 292, 1550, 318, 1856, 730, 730, 730, 29994, 382, 4875, 29994, 3413, 29994, 29899, 29994, 382, 382, 381, 1856, 382, 659, 730, 730, 291, 29994, 382, 29994, 29888, 382, 29994, 29888, 382, 29994, 1857, 1856, 382, 12921, 730, 730, 5555, 382, 382, 382, 382, 382, 29994, 382, 382, 29994, 372, 1856, 1856, 730, 382, 382, 382, 382, 382, 382, 382, 382, 382, 382, 382, 29994, 13607, 1550, 382, 6224, 4875, 29933, 382, 29933, 29923, 382, 29923, 29923, 29923, 3814, 382, 29994, 5143, 829, 5143, 29900, 1762, 262, 277, 2471, 309, 2304, 277, 766, 296, 262, 29870, 29944, 2439, 309, 7270, 29888, 296, 262, 336, 349, 5219, 29888, 471, 29870, 29944, 29899, 296, 5219, 9946, 29888, 12, 29944, 12, 2575, 3413, 29900, 1333, 1, 1093, 11855, 5427, 1, 262, 11855, 3157, 337, 829, 449, 449, 337, 277, 715, 3413, 407, 277, 936, 3157, 29888, 1, 1093, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Response:  okesExit jan f vallub iilublubaving iss– val Jullat plan–latum ,f tryir soon hall Julf– ii–ir–– while upperended–egyzetek val it–<s>––<s>–--<s><s>AN web web there mem web<s><s> elle E web iss iss memamerikan hallegyzetek upper val upper auth electronic<s> iss<s> mem hall<s><s> elle<s><s>of web issegyzetek auth auth iss iss<s><s><s> iss<s> hall e mem upper memrag upper web iss<s><s><s><s> elle<s>rag<s> thereing7<s> memegyzetek upper E memrag–те<s><s><s><s> E hallPlayer webing upperragples memAS memте<s> E E E<s><s> upper uppering theyAN E–те E E E E E issamerikanf equesfrigebraте issAS theyream soon– E E E Eing while u webтетете– E elle– č–-– E Eir web E valтетеion– E–f E–f E– current web ECCNтетеaving E E E E E– E E– it web webте E E E E E E E E E E E– ii while E{{ elleB EBE EEEE plan E–just</just0Toinit scriptil supportit disentinlubл HerilUtilfentinra Pmaryf waslubл-entmary causesf\tл\tief č0not<s>че radiusasta<s>in radiuslobal re</outout reit pl čppiticallobalf<s>че<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n"
     ]
    }
   ],
   "source": [
    "# Now decode the logits to text using the tokenizer\n",
    "lm_logits_copy = lm_logits.clone()\n",
    "lm_logits_copy = lm_logits_copy.squeeze(0)\n",
    "lm_logits_copy = lm_logits_copy.cpu().numpy()\n",
    "lm_logits_copy = lm_logits_copy[:, 1:]\n",
    "lm_logits_copy = lm_logits_copy.argmax(axis=-1)\n",
    "lm_logits_copy = lm_logits_copy.tolist()\n",
    "print(\"lm_logits: \", lm_logits_copy)\n",
    "response = tokenizer.decode(lm_logits_copy)\n",
    "print(\"Response: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_logits:  [23195, 24365, 5496, 285, 659, 29870, 13607, 29870, 29870, 5555, 1721, 29994, 659, 2739, 5066, 3814, 29994, 5066, 398, 1919, 29888, 1018, 381, 4720, 12713, 2739, 29888, 29994, 13607, 29994, 381, 29994, 29994, 1550, 7568, 2760, 29994, 23767, 659, 372, 29994, 1, 29994, 29994, 1, 29994, 29899, 29899, 1, 1, 2190, 1856, 1856, 727, 2626, 1856, 1, 1, 4875, 382, 1856, 1721, 1721, 2626, 11596, 12713, 23767, 7568, 659, 7568, 4817, 27758, 1, 1721, 1, 2626, 12713, 1, 1, 4875, 1, 1, 974, 1856, 1721, 23767, 4817, 4817, 1721, 1721, 1, 1, 1, 1721, 1, 12713, 321, 2626, 7568, 2626, 1431, 7568, 1856, 1721, 1, 1, 1, 1, 4875, 1, 1431, 1, 727, 292, 29955, 1, 2626, 23767, 7568, 382, 2626, 1431, 29994, 730, 1, 1, 1, 1, 382, 12713, 9075, 1856, 292, 7568, 1431, 2701, 2626, 3289, 2626, 730, 1, 382, 382, 382, 1, 1, 7568, 7568, 292, 896, 2190, 382, 29994, 730, 382, 382, 382, 382, 382, 1721, 11596, 29888, 321, 1912, 7932, 5869, 730, 1721, 3289, 896, 1633, 4720, 29994, 382, 382, 382, 382, 292, 1550, 318, 1856, 730, 730, 730, 29994, 382, 4875, 29994, 3413, 29994, 29899, 29994, 382, 382, 381, 1856, 382, 659, 730, 730, 291, 29994, 382, 29994, 29888, 382, 29994, 29888, 382, 29994, 1857, 1856, 382, 12921, 730, 730, 5555, 382, 382, 382, 382, 382, 29994, 382, 382, 29994, 372, 1856, 1856, 730, 382, 382, 382, 382, 382, 382, 382, 382, 382, 382, 382, 29994, 13607, 1550, 382, 6224, 4875, 29933, 382, 29933, 29923, 382, 29923, 29923, 29923, 3814, 382, 29994, 5143, 829, 5143, 29900, 1762, 262, 277, 2471, 309, 2304, 277, 766, 296, 262, 29870, 29944, 2439, 309, 7270, 29888, 296, 262, 336, 349, 5219, 29888, 471, 29870, 29944, 29899, 296, 5219, 9946, 29888, 12, 29944, 12, 2575, 3413, 29900, 1333, 1, 1093, 11855, 5427, 1, 262, 11855, 3157, 337, 829, 449, 449, 337, 277, 715, 3413, 407, 277, 936, 3157, 29888, 1, 1093, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Response:  okesExit jan f vallub iilublubaving iss– val Jullat plan–latum ,f tryir soon hall Julf– ii–ir–– while upperended–egyzetek val it–<s>––<s>–--<s><s>AN web web there mem web<s><s> elle E web iss iss memamerikan hallegyzetek upper val upper auth electronic<s> iss<s> mem hall<s><s> elle<s><s>of web issegyzetek auth auth iss iss<s><s><s> iss<s> hall e mem upper memrag upper web iss<s><s><s><s> elle<s>rag<s> thereing7<s> memegyzetek upper E memrag–те<s><s><s><s> E hallPlayer webing upperragples memAS memте<s> E E E<s><s> upper uppering theyAN E–те E E E E E issamerikanf equesfrigebraте issAS theyream soon– E E E Eing while u webтетете– E elle– č–-– E Eir web E valтетеion– E–f E–f E– current web ECCNтетеaving E E E E E– E E– it web webте E E E E E E E E E E E– ii while E{{ elleB EBE EEEE plan E–just</just0Toinit scriptil supportit disentinlubл HerilUtilfentinra Pmaryf waslubл-entmary causesf\tл\tief č0not<s>че radiusasta<s>in radiuslobal re</outout reit pl čppiticallobalf<s>че<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n"
     ]
    }
   ],
   "source": [
    "# Now decode the logits to text using the tokenizer\n",
    "import torch.nn.functional as F\n",
    "lm_logits_copy = lm_logits.clone()\n",
    "lm_logits_copy = F.softmax(lm_logits_copy, dim=-1)\n",
    "lm_logits_copy = lm_logits_copy.squeeze(0)\n",
    "lm_logits_copy = lm_logits_copy.cpu().numpy()\n",
    "lm_logits_copy = lm_logits_copy[:, 1:]\n",
    "lm_logits_copy = lm_logits_copy.argmax(axis=-1)\n",
    "lm_logits_copy = lm_logits_copy.tolist()\n",
    "print(\"lm_logits: \", lm_logits_copy)\n",
    "response = tokenizer.decode(lm_logits_copy)\n",
    "print(\"Response: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1\n",
      "original logits:  torch.Size([1, 1024, 32000])\n",
      "Response:  nobody\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def top_k_top_p_filtering(\n",
    "    logits,\n",
    "    top_k: int = 0,\n",
    "    top_p: float = 1.0,\n",
    "    filter_value: float = -float(\"Inf\"),\n",
    "    min_tokens_to_keep: int = 1,\n",
    "    ):\n",
    "    \"\"\"Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "    Source: https://huggingface.co/transformers/v3.2.0/_modules/transformers/generation_utils.html\n",
    "    \"\"\"\n",
    "    if top_k > 0:\n",
    "        top_k = min(max(top_k, min_tokens_to_keep), logits.size(-1))  # Safety check\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p < 1.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold (token with 0 are kept)\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        if min_tokens_to_keep > 1:\n",
    "            # Keep at least min_tokens_to_keep (set to min_tokens_to_keep-1 because we add the first one below)\n",
    "            sorted_indices_to_remove[..., :min_tokens_to_keep] = 0\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        # scatter sorted tensors to original indexing\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits\n",
    "\n",
    "lm_logits_copy = lm_logits.clone()\n",
    "print(\"original logits: \", lm_logits_copy.shape)\n",
    "filtered_logits = top_k_top_p_filtering(lm_logits_copy[0], top_p=0.9, top_k=1)\n",
    "probabilities = F.softmax(filtered_logits, dim=-1)\n",
    "sampled_token = torch.argmax(probabilities, dim=-1)\n",
    "response = tokenizer.decode(sampled_token[0].tolist())\n",
    "print(\"Response: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m         beam_scores \u001b[38;5;241m=\u001b[39m top_scores\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sequences\n\u001b[0;32m---> 43\u001b[0m lm_logits_copy \u001b[38;5;241m=\u001b[39m \u001b[43mlm_logits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal logits: \u001b[39m\u001b[38;5;124m\"\u001b[39m, lm_logits_copy\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     45\u001b[0m beam_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Your code here\n",
    "import torch\n",
    "\n",
    "def beam_search(logits, beam_size):\n",
    "    # Ensure beam_size is not larger than the size of the last dimension of logits[0, 0]\n",
    "    assert beam_size <= logits.size(-1), \"beam_size must be less than or equal to the size of the last dimension of logits\"\n",
    "\n",
    "    # Initialize the beam with the first token's logits and indices\n",
    "    beam_scores, beam_indices = torch.topk(logits[0, 0], beam_size)\n",
    "\n",
    "    # Initialize the sequences with the first tokens\n",
    "    sequences = beam_indices.tolist()\n",
    "\n",
    "    for i in range(1, logits.size(1)):\n",
    "        # Calculate the scores for the next tokens\n",
    "        scores, indices = torch.topk(logits[0, i], beam_size)\n",
    "\n",
    "        # Calculate the total scores for the new sequences\n",
    "        total_scores = beam_scores.view(-1, 1) + scores.view(1, -1)\n",
    "\n",
    "        # Flatten the total scores and get the top beam_size scores and their indices\n",
    "        total_scores = total_scores.view(-1)\n",
    "        top_scores, top_indices = torch.topk(total_scores, beam_size)\n",
    "\n",
    "        # Get the token indices and sequence indices for the top scores\n",
    "        next_tokens = indices.view(-1)[top_indices]\n",
    "        sequence_indices = top_indices // beam_size\n",
    "\n",
    "        # Convert sequence_indices to a list of integers\n",
    "        sequences = [[idx] for idx in beam_indices.tolist()]\n",
    "\n",
    "        # Update the sequences\n",
    "        sequences = [sequences[j] + [next_tokens[j].item()] for j in sequence_indices]\n",
    "\n",
    "        # Update the beam scores\n",
    "        beam_scores = top_scores\n",
    "\n",
    "    return sequences\n",
    "\n",
    "lm_logits_copy = lm_logits.clone()\n",
    "print(\"original logits: \", lm_logits_copy.shape)\n",
    "beam_size = 5\n",
    "sequences = beam_search(lm_logits_copy, beam_size)\n",
    "\n",
    "# Now decode the sequences to text using the tokenizer\n",
    "responses = [tokenizer.decode(sequence) for sequence in sequences]\n",
    "\n",
    "for i, response in enumerate(responses):\n",
    "    print(f\"Response {i+1}: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
